{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook for extracting theta in order to assign topics to documents.\n",
    "\n",
    "Before running this notebook, run\n",
    "1. 1.0-rw-preProcessText_makeBOW or 1.0-rw-PreProcessText_makeBOW_forTopicAssignment\n",
    "2. 1.0-rw-preProcessText2_embeddings\n",
    "3. 1.1-rw-main  (to train the model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Adji Dieng GitHub ETM\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import pickle \n",
    "import numpy as np \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import sys\n",
    "import matplotlib.pyplot as plt  \n",
    "import data\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from etm import ETM\n",
    "from utils import nearest_neighbors, get_topic_coherence, get_topic_diversity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='The Embedded Topic Model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--td'], dest='td', nargs=None, const=None, default=0, type=<class 'int'>, choices=None, help='whether to compute topic diversity or not', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### data and file related arguments\n",
    "parser.add_argument('--dataset', type=str, default='min_df_3', help='name of corpus') \n",
    "parser.add_argument('--data_path', type=str, default='data/min_df_3', help='directory containing data') \n",
    "parser.add_argument('--emb_path', type=str, default='data/min_df_3_embeddings.txt', help='directory containing word embeddings')\n",
    "parser.add_argument('--save_path', type=str, default='./results', help='path to save results')\n",
    "parser.add_argument('--batch_size', type=int, default=1000, help='input batch size for training')\n",
    "\n",
    "\n",
    "### model-related arguments\n",
    "parser.add_argument('--num_topics', type=int, default=150, help='number of topics')\n",
    "parser.add_argument('--rho_size', type=int, default=300, help='dimension of rho')\n",
    "parser.add_argument('--emb_size', type=int, default=300, help='dimension of embeddings')\n",
    "parser.add_argument('--t_hidden_size', type=int, default=800, help='dimension of hidden space of q(theta)')\n",
    "parser.add_argument('--theta_act', type=str, default='relu', help='tanh, softplus, relu, rrelu, leakyrelu, elu, selu, glu)')\n",
    "parser.add_argument('--train_embeddings', type=int, default=0, help='whether to fix rho or train it') \n",
    "\n",
    "### optimization-related arguments\n",
    "parser.add_argument('--lr', type=float, default=0.005, help='learning rate')\n",
    "parser.add_argument('--lr_factor', type=float, default=4.0, help='divide learning rate by this...')\n",
    "parser.add_argument('--epochs', type=int, default=100, help='number of epochs to train...150 for 20ng 100 for others')\n",
    "parser.add_argument('--mode', type=str, default='eval model', help='train or eval model') # default='train'\n",
    "parser.add_argument('--optimizer', type=str, default='adam', help='choice of optimizer')\n",
    "parser.add_argument('--seed', type=int, default=2019, help='random seed (default: 1)')\n",
    "parser.add_argument('--enc_drop', type=float, default=0.0, help='dropout rate on encoder')\n",
    "parser.add_argument('--clip', type=float, default=0.0, help='gradient clipping')\n",
    "parser.add_argument('--nonmono', type=int, default=10, help='number of bad hits allowed')\n",
    "parser.add_argument('--wdecay', type=float, default=1.2e-6, help='some l2 regularization')\n",
    "parser.add_argument('--anneal_lr', type=int, default=0, help='whether to anneal the learning rate or not')\n",
    "parser.add_argument('--bow_norm', type=int, default=1, help='normalize the bows or not')\n",
    "\n",
    "### evaluation, visualization, and logging-related arguments\n",
    "parser.add_argument('--num_words', type=int, default=10, help='number of words for topic viz')\n",
    "parser.add_argument('--log_interval', type=int, default=2, help='when to log training')\n",
    "parser.add_argument('--visualize_every', type=int, default=10, help='when to visualize results')\n",
    "parser.add_argument('--eval_batch_size', type=int, default=1000, help='input batch size for evaluation')\n",
    "parser.add_argument('--load_from', type=str, default='', help='the name of the ckpt to eval from')\n",
    "parser.add_argument('--tc', type=int, default=0, help='whether to compute topic coherence or not')\n",
    "parser.add_argument('--td', type=int, default=0, help='whether to compute topic diversity or not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(anneal_lr=0, batch_size=1000, bow_norm=1, clip=0.0, data_path='data/min_df_3', dataset='min_df_3', emb_path='data/min_df_3_embeddings.txt', emb_size=300, enc_drop=0.0, epochs=100, eval_batch_size=1000, load_from='', log_interval=2, lr=0.005, lr_factor=4.0, mode='eval model', nonmono=10, num_topics=150, num_words=10, optimizer='adam', rho_size=300, save_path='./results', seed=2019, t_hidden_size=800, tc=0, td=0, theta_act='relu', train_embeddings=0, visualize_every=10, wdecay=1.2e-06)\n"
     ]
    }
   ],
   "source": [
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "#args = parser.parse_args()\n",
    "# based on solution from:\n",
    "# https://stackoverflow.com/questions/48796169/how-to-fix-ipykernel-launcher-py-error-unrecognized-arguments-in-jupyter\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.load_from = \"etm_min_df_3_K_150_Htheta_800_Optim_adam_Clip_0.0_ThetaAct_relu_Lr_0.005_Bsz_1000_RhoSize_300_trainEmbeddings_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "nope\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('\\n')\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"yay\")\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "else:\n",
    "    print(\"nope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10591\n"
     ]
    }
   ],
   "source": [
    "## get data\n",
    "# 1. vocabulary\n",
    "vocab, train, valid, test = data.get_data(os.path.join(args.data_path))\n",
    "vocab_size = len(vocab)\n",
    "args.vocab_size = vocab_size\n",
    "print(args.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1658\n"
     ]
    }
   ],
   "source": [
    "# 1. training data\n",
    "train_tokens = train['tokens']\n",
    "train_counts = train['counts']\n",
    "args.num_docs_train = len(train_tokens)\n",
    "print(args.num_docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val docs\n",
      "98\n",
      "98\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "# 2. dev set\n",
    "valid_tokens = valid['tokens']\n",
    "valid_counts = valid['counts']\n",
    "args.num_docs_valid = len(valid_tokens)\n",
    "val_1_tokens = valid['tokens_1']\n",
    "val_1_counts = valid['counts_1']\n",
    "args.num_docs_valid_1 = len(val_1_tokens)\n",
    "val_2_tokens = valid['tokens_2']\n",
    "val_2_counts = valid['counts_2']\n",
    "args.num_docs_valid_2 = len(val_2_tokens)\n",
    "print(\"val docs\")\n",
    "print(args.num_docs_valid)\n",
    "print(args.num_docs_valid_1)\n",
    "print(args.num_docs_valid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test docs\n",
      "196\n",
      "196\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "# 3. test data\n",
    "test_tokens = test['tokens']\n",
    "test_counts = test['counts']\n",
    "args.num_docs_test = len(test_tokens)\n",
    "test_1_tokens = test['tokens_1']\n",
    "test_1_counts = test['counts_1']\n",
    "args.num_docs_test_1 = len(test_1_tokens)\n",
    "test_2_tokens = test['tokens_2']\n",
    "test_2_counts = test['counts_2']\n",
    "args.num_docs_test_2 = len(test_2_tokens)\n",
    "print(\"test docs\")\n",
    "print(args.num_docs_test)\n",
    "print(args.num_docs_test_1)\n",
    "print(args.num_docs_test_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
      "Training an Embedded Topic Model on MIN_DF_3 with the following settings: Namespace(anneal_lr=0, batch_size=1000, bow_norm=1, clip=0.0, data_path='data/min_df_3', dataset='min_df_3', emb_path='data/min_df_3_embeddings.txt', emb_size=300, embeddings_dim=torch.Size([10591, 300]), enc_drop=0.0, epochs=100, eval_batch_size=1000, load_from='etm_min_df_3_K_150_Htheta_800_Optim_adam_Clip_0.0_ThetaAct_relu_Lr_0.005_Bsz_1000_RhoSize_300_trainEmbeddings_0', log_interval=2, lr=0.005, lr_factor=4.0, mode='eval model', nonmono=10, num_docs_test=196, num_docs_test_1=196, num_docs_test_2=196, num_docs_train=1658, num_docs_valid=98, num_docs_valid_1=98, num_docs_valid_2=98, num_topics=150, num_words=10, optimizer='adam', rho_size=300, save_path='./results', seed=2019, t_hidden_size=800, tc=0, td=0, theta_act='relu', train_embeddings=0, visualize_every=10, vocab_size=10591, wdecay=1.2e-06)\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n"
     ]
    }
   ],
   "source": [
    "embeddings = None\n",
    "if not args.train_embeddings:\n",
    "    emb_path = args.emb_path\n",
    "#    vect_path = os.path.join(args.data_path.split('/')[0], 'embeddings.pkl')   \n",
    "    vectors = {}\n",
    "    with open(emb_path, 'rb') as f:\n",
    "        for l in f:\n",
    "            line = l.decode().split()\n",
    "            word = line[0]\n",
    "            if word in vocab:\n",
    "                vect = np.array(line[1:]).astype(np.float)\n",
    "                vectors[word] = vect\n",
    "    embeddings = np.zeros((vocab_size, args.emb_size))\n",
    "    words_found = 0\n",
    "    for i, word in enumerate(vocab):\n",
    "        try: \n",
    "            embeddings[i] = vectors[word]\n",
    "            words_found += 1\n",
    "        except KeyError:\n",
    "            embeddings[i] = np.random.normal(scale=0.6, size=(args.emb_size, ))\n",
    "    embeddings = torch.from_numpy(embeddings).to(device)\n",
    "    args.embeddings_dim = embeddings.size()\n",
    "\n",
    "print('=*'*100)\n",
    "print('Training an Embedded Topic Model on {} with the following settings: {}'.format(args.dataset.upper(), args))\n",
    "print('=*'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/etm_min_df_3_K_150_Htheta_800_Optim_adam_Clip_0.0_ThetaAct_relu_Lr_0.005_Bsz_1000_RhoSize_300_trainEmbeddings_0\n"
     ]
    }
   ],
   "source": [
    "## define checkpoint\n",
    "if not os.path.exists(args.save_path):\n",
    "    os.makedirs(args.save_path)\n",
    "\n",
    "if args.mode == 'eval model':\n",
    "    ckpt = os.path.join(args.save_path, args.load_from)\n",
    "    print(ckpt)\n",
    "else:\n",
    "    ckpt = os.path.join(args.save_path, \n",
    "        'etm_{}_K_{}_Htheta_{}_Optim_{}_Clip_{}_ThetaAct_{}_Lr_{}_Bsz_{}_RhoSize_{}_trainEmbeddings_{}_2'.format(\n",
    "        args.dataset, args.num_topics, args.t_hidden_size, args.optimizer, args.clip, args.theta_act, \n",
    "            args.lr, args.batch_size, args.rho_size, args.train_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.0)\n",
      "  (theta_act): ReLU()\n",
      "  (alphas): Linear(in_features=300, out_features=150, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=10591, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=150, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=150, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## define model and optimizer\n",
    "model = ETM(args.num_topics, vocab_size, args.t_hidden_size, args.rho_size, args.emb_size, \n",
    "                args.theta_act, embeddings, args.train_embeddings, args.enc_drop).to(device)\n",
    "\n",
    "print('model: {}'.format(model))\n",
    "\n",
    "if args.optimizer == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wdecay)\n",
    "elif args.optimizer == 'adagrad':\n",
    "    optimizer = optim.Adagrad(model.parameters(), lr=args.lr, weight_decay=args.wdecay)\n",
    "elif args.optimizer == 'adadelta':\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr, weight_decay=args.wdecay)\n",
    "elif args.optimizer == 'rmsprop':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.wdecay)\n",
    "elif args.optimizer == 'asgd':\n",
    "    optimizer = optim.ASGD(model.parameters(), lr=args.lr, t0=0, lambd=0., weight_decay=args.wdecay)\n",
    "else:\n",
    "    print('Defaulting to vanilla SGD')\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create DF with top words for each topic\n",
    "\n",
    "def create_topicsDF():\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "    ## show topics and add to topicsList\n",
    "    \n",
    "        beta = model.get_beta()\n",
    "        #topic_indices = list(np.random.choice(args.num_topics, 10)) # 10 random topics\n",
    "        print('\\n')\n",
    "        topicsList = []\n",
    "        for k in range(args.num_topics):#topic_indices:\n",
    "            gamma = beta[k]\n",
    "            top_words = list(gamma.cpu().numpy().argsort()[-args.num_words+1:][::-1])\n",
    "            topic_words = [vocab[a] for a in top_words]\n",
    "            topicsList.append(topic_words)\n",
    "            print('Topic {}: {}'.format(k, topic_words))\n",
    "     \n",
    "    ## create topicsDF and save to CSV\n",
    "    print(\"*\"*100)\n",
    "    colNames = [\"Word \" + str(i) for i in range(1, len(topicsList[1])+1)]\n",
    "    topicsDF = pd.DataFrame(topicsList, columns = colNames)\n",
    "    topicsDF = topicsDF.assign(Topic = topicsDF.index + 1)\n",
    "    fName = os.path.join(args.save_path, \"TopicDFs\", args.load_from) + \"_TOPICS.csv\"\n",
    "    \n",
    "    topicsDF.to_csv(fName)\n",
    "    return topicsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Topic 0: ['m2', 'telematic', 'automatization', 'eur', 'fogging', 'europeans', 'teammate', 'triangulation', 'haas']\n",
      "Topic 1: ['bonds', 'bp', 'qr', 'certifiers', 'column', 'grading', 'recommends', 'advises', 'ledger']\n",
      "Topic 2: ['capsid', 'studios', 'freelancers', 'programmers', 'incubators', 'virus', 'viruses', 'sequences', 'laboratories']\n",
      "Topic 3: ['defend', 'filament', 'wearer', 'pround', 'apprehend', 'govern', 'immobilization', 'domiciliary', 'violate']\n",
      "Topic 4: ['probabilistic', 'modal', 'municipal', 'hydroalcoholic', 'accreditations', 'opaque', 'stringency', 'musculoskeletal', 'pooled']\n",
      "Topic 5: ['virologists', 'gyms', 'polymerase', 'pandemics', 'nanomaterials', 'nanotechnology', 'seasoned', 'add', 'underestimate']\n",
      "Topic 6: ['fellowship', 'controller', 'upvote', 'passions', 'breakout', 'setups', 'gamer', 'likeminded', 'enabler']\n",
      "Topic 7: ['humidifier', 'checkups', 'informational', 'b2b', 'shelters', 'disinfectant', 'sterilizer', 'escrow', 'broker']\n",
      "Topic 8: ['interdisciplinary', 'transdisciplinary', 'sensorial', 'psychiatry', 'curator', 'rgb', 'sensory', 'multidisciplinary', 'celsius']\n",
      "Topic 9: ['lingual', 'contactless', 'cashless', 'triangulation', 'profiling', 'sorting', 'reclaim', 'nucleic', 'remittance']\n",
      "Topic 10: ['unstructured', 'adobe', 'tidal', 'shortness', 'explosion', '08', 'devastation', 'disasters', 'vast']\n",
      "Topic 11: ['pomodoro', 'indiegogo', 'woocommerce', 'drupal', 'opensource', 'gantt', 'versioning', 'kickstarter', 'refactored']\n",
      "Topic 12: ['vitals', 'biotechnologists', 'atlas', 'deriving', 'ehealth', 'barometer', 'forming', 'surveying', 'enters']\n",
      "Topic 13: ['nginx', 'pollutants', 'keywords', 'repo', 'convolutional', 'doers', 'iteratively', 'quarantine', 'wireframes']\n",
      "Topic 14: ['mutation', 'rollout', 'mutations', 'phased', 'videoconferences', 'coordinated', 'repeatable', 'controllable', 'smoother']\n",
      "Topic 15: ['imbalances', 'imbalance', 'shutdowns', 'pm', 'receivables', 'immunisation', 'variability', 'exposures', 'symptomatology']\n",
      "Topic 16: ['salt', 'jobseeker', 'invitations', 'pulmonologists', 'accreditations', 'congratulations', 'jobseekers', 'testimonials', 'reviews']\n",
      "Topic 17: ['serological', 'vaccinated', 'antigen', 'serology', 'intubated', 'pneumonia', 'mucosal', 'vaccine', 'antigens']\n",
      "Topic 18: ['intransparent', 'anonymization', 'functionalization', 'untreated', 'μm', 'für', 'asylum', 'relapse', 'p2p']\n",
      "Topic 19: ['telematic', 'fablab', 'fleet', 'virologists', 'carriers', 'adhesion', 'fleets', 'carrier', 'contaminations']\n",
      "Topic 20: ['coronaviruses', 'soldering', 'todos', 'mqtt', 'rhinovirus', 'immunocompromised', 'shortness', 'reinfection', 'flu']\n",
      "Topic 21: ['stethoscope', 'checkup', 'extendable', 'accessory', 'inspection', 'bundle', 'umbrella', 'testings', 'checkups']\n",
      "Topic 22: ['possess', 'mutually', 'climatic', 'positions', 'bearing', 'qualities', 'outgoing', 'probabilities', 'regenerative']\n",
      "Topic 23: ['bono', 'workflow', 'subdomain', 'councils', 'anonymisation', 'carer', 'carers', 'footfall', 'council']\n",
      "Topic 24: ['microchip', 'microchips', 'epidemiologists', 'sparks', 'upskilling', 'epidemiologist', 'retrain', 'contagiousness', 'convolutional']\n",
      "Topic 25: ['m2', 'solves', 'clarifications', 'shipments', 'misunderstandings', 'pm', 'clarification', 'normalization', 'integrations']\n",
      "Topic 26: ['logistical', 'listener', 'facilitator', 'sensory', 'complimentary', 'planner', 'itinerary', 'matchmaker', 'participant']\n",
      "Topic 27: ['leaderboards', 'leaderboard', 'auditable', 'upvote', 'confidential', 'cleanest', 'grained', 'anonymity', 'polling']\n",
      "Topic 28: ['repudiation', 'pomodoro', 'exposition', 'biotechnologists', 'conformation', 'disconnectedness', 'telework', 'teleworkers', 'immunized']\n",
      "Topic 29: ['corners', 'journalists', 'gloves', 'annotate', 'breaths', 'reviewers', 'criticism', 'branches', 'fingertip']\n",
      "Topic 30: ['randomised', 'electronical', 'fintech', 'randomized', 'matchmaking', 'telemonitoring', 'sterilizes', 'assistive', 'instruments']\n",
      "Topic 31: ['microbiome', 'disinfects', 'pneumatics', 'actuator', 'gravity', 'genetics', 'curcumin', 'lighter', 'alcohol']\n",
      "Topic 32: ['scrutiny', 'figma', 'approval', 'institution', 'público', 'unleashing', 'validation', 'governing', 'regulator']\n",
      "Topic 33: ['typescript', 'pasteur', 'figma', 'debunked', 'au', 'normalised', 'doubled', '2x', 'keras']\n",
      "Topic 34: ['laravel', 'freelancer', 'explainer', 'ethereum', 'freelancers', 'freelancing', 'likeminded', 'drupal', 'responders']\n",
      "Topic 35: ['renting', 'fullstack', 'bundle', 'sum', 'joined', 'tide', 'farmer', 'owns', 'played']\n",
      "Topic 36: ['leaderboards', 'cybersecurity', 'commoning', 'commons', 'heroku', 'arduino', 'blockchains', 'immunity', 'c16']\n",
      "Topic 37: ['greenhouse', 'sterilizing', 'sterilization', 'lighthouse', 'commissions', 'shelters', 'psychiatric', 'transfusion', 'batteries']\n",
      "Topic 38: ['wifi', 'contactless', 'strike', 'geolocation', '48h', 'accuracy', 'smartwatch', 'confort', 'posibility']\n",
      "Topic 39: ['esa', 'malnutrition', 'demotivated', 'despair', 'comprehension', 'compassion', 'empathy', 'upscaling', 'sheer']\n",
      "Topic 40: ['manipulation', 'pp', 'imbalances', 'thirds', 'developmental', 'fluctuations', 'fonts', 'pomodoro', 'moods']\n",
      "Topic 41: ['digitization', 'haystack', 'droplets', 'nanoparticles', 'fairer', 'leap', 'recession', 'mobiles', 'feces']\n",
      "Topic 42: ['brainstormed', 'empowered', 'replaceable', 'shocks', 'pandemics', 'transformations', 'contagions', 'powers', 'genetically']\n",
      "Topic 43: ['hashtag', 'laravel', 'hashtags', 'neo4j', 'json', 'tensorflow', 'electrode', 'millennials', 'tokenization']\n",
      "Topic 44: ['lenders', 'repayments', 'translators', 'telework', 'anesthesiologists', 'childcare', 'borrowers', 'escrow', 'loans']\n",
      "Topic 45: ['stethoscopes', 'microfluidic', 'linguistic', 'veterinary', 'conversational', 'lingual', 'cashless', 'randomised', 'deaf']\n",
      "Topic 46: ['collects', 'donated', 'attends', 'donate', 'fulfills', 'contacted', 'sequenced', 'protects', 'artwork']\n",
      "Topic 47: ['plague', 'infects', 'spam', 'subscribe', 'caters', 'subscribers', 'browsed', 'archived', 'infecting']\n",
      "Topic 48: ['uvc', 'trialed', 'testings', 'ingesting', 'preventative', 'housed', 'ingestion', 'ingest', 'prototyping']\n",
      "Topic 49: ['psychologically', 'relaxation', 'deconfinement', 'hats', 'lymphocytes', 'lymphopenia', 'motivates', 'infos', 'induces']\n",
      "Topic 50: ['theaters', 'democratize', 'tablets', 'deposited', 'indiegogo', 'kickstarter', 'germicidal', 'daniel', 'theatres']\n",
      "Topic 51: ['testimonials', 'income', 'paying', 'exchangeable', 'expenses', 'installing', 'psychotherapy', 'euros', 'skyrocketing']\n",
      "Topic 52: ['proctoring', 'timezones', 'reinvent', 'cross', 'buzzer', 'stakes', 'clickable', 'timezone', 'bids']\n",
      "Topic 53: ['accreditations', 'navigate', 'contactless', 'theaters', 'locals', 'horeca', 'touchless', 'primers', 'fundings']\n",
      "Topic 54: ['contagions', 'bacterium', 'neighbourhoods', 'nanomaterials', 'outbreak', 'virologist', 'pasta', 'microfluidics', 'jurisdiction']\n",
      "Topic 55: ['abuser', 'separates', 'fits', 'timezone', '2022', 'insecurity', 'postgis', 'mismatch', 'scheduler']\n",
      "Topic 56: ['internationalization', 'reallocating', 'digitalizing', 'ressources', 'intercultural', 'nanomaterials', 'neo4j', 'semester', 'processing']\n",
      "Topic 57: ['warranties', 'bikes', 'bike', 'commute', 'npm', 'preprints', 'upgrades', 'bicycle', 'warranty']\n",
      "Topic 58: ['waterproof', 'zoonotic', 'communicable', 'seal', 'recommendations', 'excited', 'webcams', 'acts', 'personalized']\n",
      "Topic 59: ['postgis', 'mongodb', 'postgresql', 'steep', 'certifiers', 'timezone', 'nucleic', 'acids', 'amino']\n",
      "Topic 60: ['portuguese', 'learners', 'leaderboard', 'timezone', 'rich', 'educating', 'judges', 'fluent', 'telling']\n",
      "Topic 61: ['2021', 'insolvency', 'gates', 'itineraries', 'adjusts', 'timezone', 'timezones', 'lasts', 'blockchains']\n",
      "Topic 62: ['internationalization', 'surf', 'transnational', 'cytometry', 'transversal', 'helmets', 'endangered', 'globalized', 'hoods']\n",
      "Topic 63: ['laravel', 'installable', 'personalized', 'auditable', 'definitive', 'straightforward', 'weighted', 'directional', 'tantamount']\n",
      "Topic 64: ['milestone', 'milestones', 'turnover', 'microphones', 'blown', 'parameter', 'speeches', 'approximation', 'exhalation']\n",
      "Topic 65: ['solenoid', 'wiring', 'endotracheal', 'intubation', 'digitalizing', 'digitalize', 'sterilizer', 'wavelength', 'digitize']\n",
      "Topic 66: ['mortar', 'finalising', 'fell', 'storming', 'bakeries', 'stone', 'hung', 'beaches', 'hanging']\n",
      "Topic 67: ['formulas', 'frontends', 'transmissions', 'vaccines', 'doses', 'vaccine', 'vez', 'programmers', 'scanners']\n",
      "Topic 68: ['troubleshoot', 'pcb', 'dots', 'links', 'geolocated', 'connections', 'bubbles', 'sticker', 'troubleshooting']\n",
      "Topic 69: ['lockdowns', 'ginger', 'toilets', 'sanitisation', 'intrusive', 'contactless', 'logins', 'inconvenience', 'inconvenient']\n",
      "Topic 70: ['p2p', 'ventilatory', 'telemonitoring', 'biometric', 'checkups', 'occupations', 'airflow', 'airway', 'gov']\n",
      "Topic 71: ['biosafety', 'precautionary', 'postponing', 'cashless', 'postponed', 'bans', 'ban', 'participative', 'gamify']\n",
      "Topic 72: ['convolutional', 'relieve', 'decongestion', 'eng', 'sweat', 'prisoners', 'collar', 'telegram', 'dear']\n",
      "Topic 73: ['anonymization', 'opendata', 'virology', 'incubators', 'gases', 'tide', 'dept', 'epidemiologic', 'receivables']\n",
      "Topic 74: ['finalised', 'exhaustion', 'finalise', 'galaxy', 'rumours', 'virologists', 'coronaviruses', 'confidentiality', 'carers']\n",
      "Topic 75: ['tears', 'sew', 'realised', 'prolongs', 'deducted', 'fruitful', 'recognises', 'learnt', 'incurred']\n",
      "Topic 76: ['ago', 'biometrics', 'encryption', 'badge', 'pride', 'badges', 'delay', 'inactivity', 'mitigations']\n",
      "Topic 77: ['coronavirus', 'bono', 'globalization', 'pasteur', 'immunocompromised', 'ibm', 'biometrics', 'paralysis', 'centralization']\n",
      "Topic 78: ['decentralize', 'automatize', 'browsers', 'sqlite', 'cashless', 'unbanked', 'retrain', 'compile', 'encrypt']\n",
      "Topic 79: ['fertility', 'vitro', 'coli', 'dairy', 'property', 'cultures', 'statuses', 'furlough', 'telepresence']\n",
      "Topic 80: ['navigation', 'css3', 'advertisers', 'fallback', 'frontend', 'woocommerce', 'subscriptions', 'hardcoded', 'lifestyle']\n",
      "Topic 81: ['thermometers', 'stethoscopes', 'sockets', 'celsius', 'psychiatric', 'adhesive', 'oximeters', 'stethoscope', 'uvc']\n",
      "Topic 82: ['hiv', 'bankruptcy', 'diagnose', 'mayor', 'symptoms', 'herpes', 'traumatic', 'pathologies', 'paperwork']\n",
      "Topic 83: ['architect', 'minimalist', 'rgb', 'pivots', 'occupies', 'stake', 'pivot', 'leak', 'sensorial']\n",
      "Topic 84: ['concentration', 'headsets', 'headset', 'settlements', 'telepresence', 'concentrations', 'cities', 'corporations', 'microphones']\n",
      "Topic 85: ['honest', 'resilient', 'reputable', 'scams', 'thrived', 'matchmaker', 'lucky', 'cheating', 'dealt']\n",
      "Topic 86: ['resiliency', 'anonymity', 'heal', 'vulnerabilities', 'builds', 'crossings', 'citizenship', 'vulnerability', 'longitudinal']\n",
      "Topic 87: ['stored', 'storing', 'μm', 'lockdowns', 'encrypting', 'gantt', 'permissioned', '48h', 'metadata']\n",
      "Topic 88: ['professors', 'publications', 'mqtt', 'brochures', 'abstracts', 'opendata', 'leaflets', 'alerts', 'preprints']\n",
      "Topic 89: ['mentorships', 'steps', 'scholar', 'quarantined', 'researched', 'traced', 'learned', 'downloaded', 'fostered']\n",
      "Topic 90: ['giver', 'contagiousness', 'contagious', 'infectious', 'infective', 'electronical', 'toilet', 'courage', 'contactless']\n",
      "Topic 91: ['fairer', 'evolved', 'fleshed', 'piloted', 'standardised', 'trialed', 'greener', 'hospitalised', 'fought']\n",
      "Topic 92: ['miscommunication', 'accomplishment', 'disconnectedness', 'boredom', 'sadness', 'socialization', 'discord', 'progression', 'coped']\n",
      "Topic 93: ['straps', 'knees', 'adheres', 'specializations', 'mesh', 'differ', 'wireframe', 'attention', 'pedestrian']\n",
      "Topic 94: ['fledged', 'aerosols', 'addressable', 'helplines', 'advertisement', 'motivational', 'clickable', 'donators', 'crysis']\n",
      "Topic 95: ['hyperlocal', 'furloughed', 'footfall', 'instagram', 'decongestion', 'errands', 'hip', 'anxiety', 'faith']\n",
      "Topic 96: ['outage', 'demotivated', 'uplift', 'npm', 'manager', 'outages', 'backoffice', 'sms', 'unlock']\n",
      "Topic 97: ['mqtt', 'crypto', 'hydroalcoholic', 'bioavailability', 'ethereum', 'middleman', 'automates', 'cryptocurrency', 'geofencing']\n",
      "Topic 98: ['recommender', 'forums', 'registries', 'registry', 'outbreak', 'enthusiast', 'chatbots', 'addon', 'gamification']\n",
      "Topic 99: ['earthquakes', 'earthquake', 'zoonotic', 'bikes', 'telemedicine', 'telehealth', 'propagation', 'telemonitoring', 'bicycles']\n",
      "Topic 100: ['sedentary', 'continental', 'typology', 'distinction', 'broad', 'western', 'terrain', 'century', 'breadth']\n",
      "Topic 101: ['fatality', 'fatalities', 'deaths', 'liability', 'irreversible', 'immutable', 'uncertainty', 'immutability', 'mortality']\n",
      "Topic 102: ['milions', 'cancer', 'pets', 'robots', 'pet', 'más', 'refund', 'requests', 'haystack']\n",
      "Topic 103: ['bpm', 'kubernetes', 'heroku', 'serverless', 'neo4j', 'personalised', 'postgresql', 'mindfulness', 'functionalization']\n",
      "Topic 104: ['npm', 'recession', 'jobseeker', 'infographics', 'upvote', 'employability', 'jobseekers', 'monetize', 'nginx']\n",
      "Topic 105: ['adobe', 'gamify', 'hiv', 'canva', 'commoning', 'indiegogo', 'typescript', 'kickstarter', 'reinfection']\n",
      "Topic 106: ['resuscitator', 'slack', 'preprint', 'caregiving', 'newsroom', 'cancellations', 'scheduler', 'streamlining', 'unused']\n",
      "Topic 107: ['literacy', 'divided', 'drawing', 'journalism', 'drew', 'illiteracy', 'typing', 'sponsorships', 'postal']\n",
      "Topic 108: ['fintechs', 'adobe', 'videoconferencing', 'chatbots', 'videoconference', 'trailer', 'modernization', 'undergoing', 'fleets']\n",
      "Topic 109: ['simulators', 'bodies', 'avatars', 'simulator', 'customise', 'teammates', 'simulation', 'sim', 'survivors']\n",
      "Topic 110: ['bootstrapping', 'npm', 'mongodb', 'bootstrapped', 'allies', 'bootstrap', 'postgresql', 'funders', 'neo4j']\n",
      "Topic 111: ['cytometry', 'anonymised', 'granularity', 'pomodoro', 'anonymized', 'boundaries', 'epidemiology', 'synchronisation', 'malaria']\n",
      "Topic 112: ['golang', 'jwt', 'sterilise', 'webserver', 'postgis', 'directory', 'bootstrap', 'aws', 'maintainable']\n",
      "Topic 113: ['firewalls', 'workstations', 'postgis', 'teleworkers', 'onboarded', 'crunch', 'blueprints', 'telemonitoring', 'staffing']\n",
      "Topic 114: ['timezones', 'soldering', 'commoning', 'mqtt', 'biotechnologists', 'circuits', 'timezone', 'neurons', 'electrode']\n",
      "Topic 115: ['keras', 'redis', 'visualisations', 'tensorflow', 'heroku', 'visualisation', 'visualizations', 'auditable', 'digitize']\n",
      "Topic 116: ['maintainable', 'nginx', 'durable', 'sterilizable', '501', 'arduino', 'sponsor', 'pins', 'loops']\n",
      "Topic 117: ['teleconsultation', 'timezones', 'auscultation', 'ventilatory', 'automatized', 'responder', 'paced', 'spreaders', 'aggregators']\n",
      "Topic 118: ['postgis', 'curves', 'playgrounds', 'readme', 'drafting', 'sandbox', 'suspended', 'exercising', 'mouse']\n",
      "Topic 119: ['unbanked', 'saves', 'saving', 'reusing', 'hackers', 'untapped', 'planet', 'hacker', 'laptop']\n",
      "Topic 120: ['atoms', 'fakes', 'immutability', 'inhibit', 'barriers', 'pride', 'fidelity', 'visibility', 'sexual']\n",
      "Topic 121: ['parliament', 'election', 'elections', 'chatbot', 'genome', 'queueing', 'queues', 'census', 'chatbots']\n",
      "Topic 122: ['methacrylate', 'gowns', 'studio', 'servants', 'exclusive', 'fellowship', 'privilege', 'newly', 'ensemble']\n",
      "Topic 123: ['portuguese', 'heatmap', 'hoarding', 'preprocessing', 'overproduction', 'printing', 'crypto', 'automatization', 'personalization']\n",
      "Topic 124: ['onboarded', 'checkup', 'spreaders', 'checkups', 'suicides', 'teleworking', 'layoffs', 'mailed', 'van']\n",
      "Topic 125: ['farm', 'franchise', 'owns', 'storytellers', 'premises', 'oldest', 'pub', 'tracheal', 'owners']\n",
      "Topic 126: ['curfew', 'unbanked', 'signing', 'club', 'clubs', 'memberships', 'bar', 'fiat', 'frictionless']\n",
      "Topic 127: ['permissioned', 'woocommerce', 'plataforma', 'photoshop', 'editable', 'quizzes', 'png', 'frontends', 'tutorials']\n",
      "Topic 128: ['germ', 'overproduction', 'hoc', 'lymphopenia', 'biosafety', 'hematopoietic', 'cytokine', 'recruiters', 'refugee']\n",
      "Topic 129: ['allergy', 'culinary', 'recognize', 'curiosity', 'recognise', 'recognition', 'puzzle', 'hunger', 'pleasure']\n",
      "Topic 130: ['alumni', 'incurred', 'directors', 'shareholders', 'joins', 'geographies', 'names', 'collaborated', 'architects']\n",
      "Topic 131: ['postgresql', 'sqlite', 'plataforma', 'cfm', 'corridors', 'dropout', 'buffers', 'chambers', 'youtube']\n",
      "Topic 132: ['xray', 'leaderboards', 'omnichannel', 'internships', 'breathe', 'rankings', 'spotify', 'oxygen', 'oxygenation']\n",
      "Topic 133: ['commercialisation', 'distinction', 'realisation', 'analyser', 'authenticity', 'esa', 'authentic', 'moon', 'effortless']\n",
      "Topic 134: ['stethoscope', 'centrally', 'humidifier', 'h2o', 'sterilizable', 'washable', 'ventilating', 'delegated', 'securely']\n",
      "Topic 135: ['analyst', 'touchpoint', 'strategist', 'cashback', 'barcode', 'crysis', 'helmet', 'logo', 'analysts']\n",
      "Topic 136: ['hematopoietic', 'cytometry', 'fintechs', 'angiotensin', 'elixir', 'influencer', 'uno', 'criticality', 'authenticating']\n",
      "Topic 137: ['angiotensin', 'converting', 'disability', 'religion', 'vaccinations', 'medications', 'globalization', 'abusers', 'unleashing']\n",
      "Topic 138: ['800', '500', '700', '400', '900', '850', 'ingest', '600', '950']\n",
      "Topic 139: ['cnc', 'visa', 'passport', 'grained', 'neo4j', 'convolutional', 'seal', 'videoconference', 'mongodb']\n",
      "Topic 140: ['uvc', 'recommender', 'workflow', 'biases', 'silico', 'inspections', 'horeca', 'conformation', 'malaria']\n",
      "Topic 141: ['polycarbonate', 'pomodoro', 'moderators', 'upvote', 'penetrate', 'trace', 'cures', 'paste', 'cheese']\n",
      "Topic 142: ['dyslexia', 'assistive', 'hurdle', 'autism', 'conclusive', 'forensics', 'disabilities', 'tokenization', 'proctoring']\n",
      "Topic 143: ['auf', 'anonymisation', 'feedbacks', 'temperature', 'weather', 'laravel', 'confinement', 'absorption', 'temp']\n",
      "Topic 144: ['emitted', 'inhalation', 'wake', 'emit', 'emissions', 'inspiratory', 'inhale', 'threaten', 'exhale']\n",
      "Topic 145: ['conversational', 'telegram', 'kindergartens', 'replies', 'domino', 'plataforma', 'passive', 'groundwork', 'synchronisation']\n",
      "Topic 146: ['donators', 'methacrylate', 'pasteur', 'hoc', 'woocommerce', 'ionic', 'peroxide', 'ressources', 'testimonials']\n",
      "Topic 147: ['ideation', 'wireframing', 'participative', 'pround', 'comprehensible', 'intends', 'democratic', 'edutainment', 'reproduce']\n",
      "Topic 148: ['anosmia', 'loaded', 'caregiver', 'caregivers', 'parsed', 'caregiving', 'ended', 'popped', 'fed']\n",
      "Topic 149: ['decongestion', 'insolvency', 'neighbourhoods', 'subsidies', 'solvency', 'unions', 'opendata', 'permissions', 'warranties']\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m2</td>\n",
       "      <td>telematic</td>\n",
       "      <td>automatization</td>\n",
       "      <td>eur</td>\n",
       "      <td>fogging</td>\n",
       "      <td>europeans</td>\n",
       "      <td>teammate</td>\n",
       "      <td>triangulation</td>\n",
       "      <td>haas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bonds</td>\n",
       "      <td>bp</td>\n",
       "      <td>qr</td>\n",
       "      <td>certifiers</td>\n",
       "      <td>column</td>\n",
       "      <td>grading</td>\n",
       "      <td>recommends</td>\n",
       "      <td>advises</td>\n",
       "      <td>ledger</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capsid</td>\n",
       "      <td>studios</td>\n",
       "      <td>freelancers</td>\n",
       "      <td>programmers</td>\n",
       "      <td>incubators</td>\n",
       "      <td>virus</td>\n",
       "      <td>viruses</td>\n",
       "      <td>sequences</td>\n",
       "      <td>laboratories</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>defend</td>\n",
       "      <td>filament</td>\n",
       "      <td>wearer</td>\n",
       "      <td>pround</td>\n",
       "      <td>apprehend</td>\n",
       "      <td>govern</td>\n",
       "      <td>immobilization</td>\n",
       "      <td>domiciliary</td>\n",
       "      <td>violate</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>probabilistic</td>\n",
       "      <td>modal</td>\n",
       "      <td>municipal</td>\n",
       "      <td>hydroalcoholic</td>\n",
       "      <td>accreditations</td>\n",
       "      <td>opaque</td>\n",
       "      <td>stringency</td>\n",
       "      <td>musculoskeletal</td>\n",
       "      <td>pooled</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word 1     Word 2          Word 3          Word 4          Word 5  \\\n",
       "0             m2  telematic  automatization             eur         fogging   \n",
       "1          bonds         bp              qr      certifiers          column   \n",
       "2         capsid    studios     freelancers     programmers      incubators   \n",
       "3         defend   filament          wearer          pround       apprehend   \n",
       "4  probabilistic      modal       municipal  hydroalcoholic  accreditations   \n",
       "\n",
       "      Word 6          Word 7           Word 8        Word 9  Topic  \n",
       "0  europeans        teammate    triangulation          haas      1  \n",
       "1    grading      recommends          advises        ledger      2  \n",
       "2      virus         viruses        sequences  laboratories      3  \n",
       "3     govern  immobilization      domiciliary       violate      4  \n",
       "4     opaque      stringency  musculoskeletal        pooled      5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicsDF = create_topicsDF()\n",
    "topicsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the beta matrix (word distribution over topics) associated to model\n",
    "\n",
    "def get_betaMatrix(m):\n",
    "\n",
    "    beta = m.get_beta()\n",
    "    beta = beta.detach().numpy()\n",
    "\n",
    "    path_save = os.path.join(args.save_path, \"ThetaBeta\", args.load_from)\n",
    "    with open(path_save + '_beta.pkl', 'wb') as f:\n",
    "            pickle.dump(beta, f)\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 10591)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = get_betaMatrix(m = model)\n",
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the theta matrix (topic distribution over documents) associated to model and docs\n",
    "\n",
    "def get_thetaMatrix(m, source = \"test\"):\n",
    "    # first create null theta DF\n",
    "    \n",
    "    totalTheta = pd.DataFrame()\n",
    "    \n",
    "    # prepare indices and tokens\n",
    "    if source == \"train\":\n",
    "        indices = torch.split(torch.tensor(range(args.num_docs_train)), args.eval_batch_size)\n",
    "        tokens = train_tokens\n",
    "        counts = train_counts\n",
    "    else:\n",
    "        indices = torch.split(torch.tensor(range(args.num_docs_test)), args.eval_batch_size)\n",
    "        tokens = test_tokens\n",
    "        counts = test_counts\n",
    "        \n",
    "    ## split into batch sizes and get \\theta here (theta contains topic assignments)    \n",
    "    for idx, ind in enumerate(indices):\n",
    "        ## get theta from first half of docs\n",
    "        data_batch = data.get_batch(tokens, counts, ind, args.vocab_size, device)\n",
    "        sums = data_batch.sum(1).unsqueeze(1)\n",
    "        if args.bow_norm:\n",
    "            normalized_data_batch = data_batch / sums\n",
    "        else:\n",
    "            normalized_data_batch = data_batch\n",
    "        \n",
    "        theta, _ = m.get_theta(normalized_data_batch)\n",
    "\n",
    "        ## combine with theta from previous batch\n",
    "        th = theta.detach().numpy()\n",
    "        th = pd.DataFrame(th)\n",
    "        totalTheta = totalTheta.append(th.copy())\n",
    "    \n",
    "    # Save the file\n",
    "    path_save = os.path.join(args.save_path, \"ThetaBeta\", args.load_from)\n",
    "    print(\"Saving to: {}\".format(path_save))\n",
    "    with open(path_save + '_theta.pkl', 'wb') as f:\n",
    "        pickle.dump(totalTheta, f)\n",
    "        \n",
    "    return(totalTheta.reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: ./results/ThetaBeta/etm_min_df_3_K_150_Htheta_800_Optim_adam_Clip_0.0_ThetaAct_relu_Lr_0.005_Bsz_1000_RhoSize_300_trainEmbeddings_0\n"
     ]
    }
   ],
   "source": [
    "thetaDF = get_thetaMatrix(m = model, source = \"train\")  # source = 'train' or 'test'\n",
    "thetaDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>Topic_8</th>\n",
       "      <th>Topic_9</th>\n",
       "      <th>Topic_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_142</th>\n",
       "      <th>Topic_143</th>\n",
       "      <th>Topic_144</th>\n",
       "      <th>Topic_145</th>\n",
       "      <th>Topic_146</th>\n",
       "      <th>Topic_147</th>\n",
       "      <th>Topic_148</th>\n",
       "      <th>Topic_149</th>\n",
       "      <th>Topic_150</th>\n",
       "      <th>newIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.006595</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.006774</td>\n",
       "      <td>0.006768</td>\n",
       "      <td>0.006511</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.006630</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.006894</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>0.006478</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006727</td>\n",
       "      <td>0.006595</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006772</td>\n",
       "      <td>0.006511</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.006552</td>\n",
       "      <td>0.006634</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>0.006478</td>\n",
       "      <td>0.006455</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>0.006618</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006727</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0.006740</td>\n",
       "      <td>0.006773</td>\n",
       "      <td>0.006766</td>\n",
       "      <td>0.006510</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>0.006606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>0.006894</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.006520</td>\n",
       "      <td>0.006478</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic_1   Topic_2   Topic_3   Topic_4   Topic_5   Topic_6   Topic_7  \\\n",
       "0  0.006726  0.006595  0.006741  0.006774  0.006768  0.006511  0.006350   \n",
       "1  0.006727  0.006595  0.006745  0.006770  0.006772  0.006511  0.006356   \n",
       "2  0.006727  0.006594  0.006740  0.006773  0.006766  0.006510  0.006351   \n",
       "\n",
       "    Topic_8   Topic_9  Topic_10    ...     Topic_142  Topic_143  Topic_144  \\\n",
       "0  0.006551  0.006630  0.006608    ...      0.006847   0.006894   0.006783   \n",
       "1  0.006552  0.006634  0.006603    ...      0.006852   0.006891   0.006782   \n",
       "2  0.006550  0.006629  0.006606    ...      0.006846   0.006894   0.006783   \n",
       "\n",
       "   Topic_145  Topic_146  Topic_147  Topic_148  Topic_149  Topic_150  newIndex  \n",
       "0   0.006519   0.006478   0.006451   0.006546   0.006619   0.006842         0  \n",
       "1   0.006515   0.006478   0.006455   0.006545   0.006618   0.006840         1  \n",
       "2   0.006520   0.006478   0.006450   0.006546   0.006619   0.006839         2  \n",
       "\n",
       "[3 rows x 151 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the column headings\n",
    "thetaDF.rename(columns=lambda x: 'Topic_' + str(x + 1), inplace=True)\n",
    "thetaDF = thetaDF.assign(newIndex = thetaDF.index)\n",
    "thetaDF.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Challenge</th>\n",
       "      <th>SubChallenge</th>\n",
       "      <th>ProjURL</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>oldIndex</th>\n",
       "      <th>fullDS</th>\n",
       "      <th>newIndex</th>\n",
       "      <th>permuteIdx</th>\n",
       "      <th>vocabDS</th>\n",
       "      <th>dsType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Business</td>\n",
       "      <td>NewModels</td>\n",
       "      <td>https://devpost.com/software/connecting-future...</td>\n",
       "      <td>Connecting Futures</td>\n",
       "      <td>The problem your project solves\\nProblem: Huge...</td>\n",
       "      <td>963</td>\n",
       "      <td>[11787, 11798, 11507, 10180, 11645, 11201, 113...</td>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>[10180, 3114, 8032, 10530, 10285, 10530, 10285...</td>\n",
       "      <td>Tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>Health</td>\n",
       "      <td>Other</td>\n",
       "      <td>https://devpost.com/software/aurum-wellness</td>\n",
       "      <td>Aurum Wellness</td>\n",
       "      <td>Inspiration - Always wanted to work in the spa...</td>\n",
       "      <td>889</td>\n",
       "      <td>[11058, 11789, 11358, 10434, 11268, 11577, 114...</td>\n",
       "      <td>804</td>\n",
       "      <td>1</td>\n",
       "      <td>[10434, 10434, 10176, 8544, 10517]</td>\n",
       "      <td>Tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>Business</td>\n",
       "      <td>Other</td>\n",
       "      <td>https://devpost.com/software/desktop-mobile-co...</td>\n",
       "      <td>Desktop mobile computer</td>\n",
       "      <td>The problem\\nThere is a problem that need shor...</td>\n",
       "      <td>1269</td>\n",
       "      <td>[11787, 11787, 11800, 11780, 10482, 11532, 116...</td>\n",
       "      <td>1155</td>\n",
       "      <td>2</td>\n",
       "      <td>[10482, 4194, 9529, 6383, 10505, 8577, 10529, ...</td>\n",
       "      <td>Tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>Cohesion</td>\n",
       "      <td>FakeNews</td>\n",
       "      <td>https://devpost.com/software/fact-o-meter-47w15x</td>\n",
       "      <td>Fact-O-Meter</td>\n",
       "      <td>The story of Pinocchio and his nose:\\nFake New...</td>\n",
       "      <td>1435</td>\n",
       "      <td>[10628, 11144, 9579, 4649, 645, 10023, 10, 117...</td>\n",
       "      <td>1311</td>\n",
       "      <td>3</td>\n",
       "      <td>[9579, 4649, 645, 10023, 10, 9042, 10211, 1011...</td>\n",
       "      <td>Tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Health</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>https://devpost.com/software/tracejyu</td>\n",
       "      <td>TraceJYU</td>\n",
       "      <td>Inspiration\\nWe are inspired by the need to fi...</td>\n",
       "      <td>62</td>\n",
       "      <td>[11275, 11767, 11800, 11772, 11720, 10823, 116...</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>[9684, 10304, 9091, 9997, 6891, 7581, 10327, 9...</td>\n",
       "      <td>Tr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Challenge SubChallenge  \\\n",
       "871   Business    NewModels   \n",
       "804     Health        Other   \n",
       "1155  Business        Other   \n",
       "1311  Cohesion     FakeNews   \n",
       "59      Health    Equipment   \n",
       "\n",
       "                                                ProjURL  \\\n",
       "871   https://devpost.com/software/connecting-future...   \n",
       "804         https://devpost.com/software/aurum-wellness   \n",
       "1155  https://devpost.com/software/desktop-mobile-co...   \n",
       "1311   https://devpost.com/software/fact-o-meter-47w15x   \n",
       "59                https://devpost.com/software/tracejyu   \n",
       "\n",
       "                        title  \\\n",
       "871        Connecting Futures   \n",
       "804            Aurum Wellness   \n",
       "1155  Desktop mobile computer   \n",
       "1311             Fact-O-Meter   \n",
       "59                   TraceJYU   \n",
       "\n",
       "                                                   text  oldIndex  \\\n",
       "871   The problem your project solves\\nProblem: Huge...       963   \n",
       "804   Inspiration - Always wanted to work in the spa...       889   \n",
       "1155  The problem\\nThere is a problem that need shor...      1269   \n",
       "1311  The story of Pinocchio and his nose:\\nFake New...      1435   \n",
       "59    Inspiration\\nWe are inspired by the need to fi...        62   \n",
       "\n",
       "                                                 fullDS  newIndex  permuteIdx  \\\n",
       "871   [11787, 11798, 11507, 10180, 11645, 11201, 113...       871           0   \n",
       "804   [11058, 11789, 11358, 10434, 11268, 11577, 114...       804           1   \n",
       "1155  [11787, 11787, 11800, 11780, 10482, 11532, 116...      1155           2   \n",
       "1311  [10628, 11144, 9579, 4649, 645, 10023, 10, 117...      1311           3   \n",
       "59    [11275, 11767, 11800, 11772, 11720, 10823, 116...        59           4   \n",
       "\n",
       "                                                vocabDS dsType  \n",
       "871   [10180, 3114, 8032, 10530, 10285, 10530, 10285...     Tr  \n",
       "804                  [10434, 10434, 10176, 8544, 10517]     Tr  \n",
       "1155  [10482, 4194, 9529, 6383, 10505, 8577, 10529, ...     Tr  \n",
       "1311  [9579, 4649, 645, 10023, 10, 9042, 10211, 1011...     Tr  \n",
       "59    [9684, 10304, 9091, 9997, 6891, 7581, 10327, 9...     Tr  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the df with the document info\n",
    "\n",
    "with open(os.path.join('./data', 'min_df_3', 'dataDF.pkl'), 'rb') as f:\n",
    "        newDF = pickle.load(f)\n",
    "\n",
    "        \n",
    "# rearrange df by permuteIdx, since this is the order they appear in in the topic embeddings\n",
    "newDF.sort_values(by = \"permuteIdx\", axis=0, ascending=True, inplace=True, kind='quicksort', na_position='last')\n",
    "newDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Challenge</th>\n",
       "      <th>SubChallenge</th>\n",
       "      <th>ProjURL</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>oldIndex</th>\n",
       "      <th>fullDS</th>\n",
       "      <th>newIndex</th>\n",
       "      <th>permuteIdx</th>\n",
       "      <th>vocabDS</th>\n",
       "      <th>dsType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>https://devpost.com/software/psychological-fir...</td>\n",
       "      <td>Helpers</td>\n",
       "      <td>Inspiration\\nWhat it does\\nHow I built it\\nCha...</td>\n",
       "      <td>2091</td>\n",
       "      <td>[11804, 11796, 11797, 11795]</td>\n",
       "      <td>1904</td>\n",
       "      <td>274</td>\n",
       "      <td>[]</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Health</td>\n",
       "      <td>Ventilators</td>\n",
       "      <td>https://devpost.com/software/nose-filter-for-a...</td>\n",
       "      <td>Nose filter for air that u breathe!</td>\n",
       "      <td>Inspiration\\njust had the idea for a long time...</td>\n",
       "      <td>188</td>\n",
       "      <td>[11769, 11716, 11804, 11796, 11797, 11795, 107...</td>\n",
       "      <td>173</td>\n",
       "      <td>308</td>\n",
       "      <td>[]</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>Business</td>\n",
       "      <td>Customers</td>\n",
       "      <td>https://devpost.com/software/test1-6b0ugv</td>\n",
       "      <td>To be renamed</td>\n",
       "      <td>Inspiration\\n... coming soon\\nWhat it does\\n.....</td>\n",
       "      <td>1218</td>\n",
       "      <td>[11253, 11253, 11804, 11253, 11796, 11253, 117...</td>\n",
       "      <td>1107</td>\n",
       "      <td>342</td>\n",
       "      <td>[]</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>Business</td>\n",
       "      <td>TeamWork</td>\n",
       "      <td>https://devpost.com/software/business-news-t4kqp3</td>\n",
       "      <td>business-news</td>\n",
       "      <td>In the current scenario of the world, it is ha...</td>\n",
       "      <td>910</td>\n",
       "      <td>[11768, 10863, 11512, 11492, 11789, 11745, 117...</td>\n",
       "      <td>822</td>\n",
       "      <td>514</td>\n",
       "      <td>[]</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>Business</td>\n",
       "      <td>NewModels</td>\n",
       "      <td>https://devpost.com/software/eurovirtual</td>\n",
       "      <td>eurovirtual</td>\n",
       "      <td>Inspiration THE VIRTUAL WORLD\\nWhat it does EA...</td>\n",
       "      <td>931</td>\n",
       "      <td>[11804, 11796, 11797, 11795]</td>\n",
       "      <td>842</td>\n",
       "      <td>557</td>\n",
       "      <td>[]</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>Business</td>\n",
       "      <td>Customers</td>\n",
       "      <td>https://devpost.com/software/test-5zy6wr</td>\n",
       "      <td>Test</td>\n",
       "      <td>Inspiration\\nTrying to see what happens after ...</td>\n",
       "      <td>1205</td>\n",
       "      <td>[11804, 11796, 11797, 11795]</td>\n",
       "      <td>1097</td>\n",
       "      <td>1012</td>\n",
       "      <td>[]</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Business</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>https://devpost.com/software/covid19-erp-d3m7qu</td>\n",
       "      <td>Covid19-ERP</td>\n",
       "      <td>the need to provide Big Data &amp; Analitica funct...</td>\n",
       "      <td>1093</td>\n",
       "      <td>[11776, 11721, 11258, 11792, 11726, 11735, 106...</td>\n",
       "      <td>994</td>\n",
       "      <td>1034</td>\n",
       "      <td>[]</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Health</td>\n",
       "      <td>CommunicationPrevention</td>\n",
       "      <td>https://devpost.com/software/coronitor-pharmac...</td>\n",
       "      <td>coronitor - Pharmacy Extension</td>\n",
       "      <td>Inspiration\\nWhat it does\\nHow I built it\\nCha...</td>\n",
       "      <td>541</td>\n",
       "      <td>[11804, 11796, 11797, 11795]</td>\n",
       "      <td>492</td>\n",
       "      <td>1472</td>\n",
       "      <td>[]</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Health</td>\n",
       "      <td>CommunicationPrevention</td>\n",
       "      <td>https://devpost.com/software/smart-workout-hea...</td>\n",
       "      <td>Smart-Workout/Health-Equipment= BooChiCa</td>\n",
       "      <td>Inspiration ONLINE WORKOUT\\nWhat it does MONIT...</td>\n",
       "      <td>281</td>\n",
       "      <td>[11804, 11796, 11797, 11795]</td>\n",
       "      <td>257</td>\n",
       "      <td>1922</td>\n",
       "      <td>[]</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Challenge             SubChallenge  \\\n",
       "1904     Other                    Other   \n",
       "173     Health              Ventilators   \n",
       "1107  Business                Customers   \n",
       "822   Business                 TeamWork   \n",
       "842   Business                NewModels   \n",
       "1097  Business                Customers   \n",
       "994   Business                Logistics   \n",
       "492     Health  CommunicationPrevention   \n",
       "257     Health  CommunicationPrevention   \n",
       "\n",
       "                                                ProjURL  \\\n",
       "1904  https://devpost.com/software/psychological-fir...   \n",
       "173   https://devpost.com/software/nose-filter-for-a...   \n",
       "1107          https://devpost.com/software/test1-6b0ugv   \n",
       "822   https://devpost.com/software/business-news-t4kqp3   \n",
       "842            https://devpost.com/software/eurovirtual   \n",
       "1097           https://devpost.com/software/test-5zy6wr   \n",
       "994     https://devpost.com/software/covid19-erp-d3m7qu   \n",
       "492   https://devpost.com/software/coronitor-pharmac...   \n",
       "257   https://devpost.com/software/smart-workout-hea...   \n",
       "\n",
       "                                         title  \\\n",
       "1904                                   Helpers   \n",
       "173        Nose filter for air that u breathe!   \n",
       "1107                             To be renamed   \n",
       "822                              business-news   \n",
       "842                                eurovirtual   \n",
       "1097                                      Test   \n",
       "994                                Covid19-ERP   \n",
       "492             coronitor - Pharmacy Extension   \n",
       "257   Smart-Workout/Health-Equipment= BooChiCa   \n",
       "\n",
       "                                                   text  oldIndex  \\\n",
       "1904  Inspiration\\nWhat it does\\nHow I built it\\nCha...      2091   \n",
       "173   Inspiration\\njust had the idea for a long time...       188   \n",
       "1107  Inspiration\\n... coming soon\\nWhat it does\\n.....      1218   \n",
       "822   In the current scenario of the world, it is ha...       910   \n",
       "842   Inspiration THE VIRTUAL WORLD\\nWhat it does EA...       931   \n",
       "1097  Inspiration\\nTrying to see what happens after ...      1205   \n",
       "994   the need to provide Big Data & Analitica funct...      1093   \n",
       "492   Inspiration\\nWhat it does\\nHow I built it\\nCha...       541   \n",
       "257   Inspiration ONLINE WORKOUT\\nWhat it does MONIT...       281   \n",
       "\n",
       "                                                 fullDS  newIndex  permuteIdx  \\\n",
       "1904                       [11804, 11796, 11797, 11795]      1904         274   \n",
       "173   [11769, 11716, 11804, 11796, 11797, 11795, 107...       173         308   \n",
       "1107  [11253, 11253, 11804, 11253, 11796, 11253, 117...      1107         342   \n",
       "822   [11768, 10863, 11512, 11492, 11789, 11745, 117...       822         514   \n",
       "842                        [11804, 11796, 11797, 11795]       842         557   \n",
       "1097                       [11804, 11796, 11797, 11795]      1097        1012   \n",
       "994   [11776, 11721, 11258, 11792, 11726, 11735, 106...       994        1034   \n",
       "492                        [11804, 11796, 11797, 11795]       492        1472   \n",
       "257                        [11804, 11796, 11797, 11795]       257        1922   \n",
       "\n",
       "     vocabDS dsType  \n",
       "1904      []     NA  \n",
       "173       []     NA  \n",
       "1107      []     NA  \n",
       "822       []     NA  \n",
       "842       []     NA  \n",
       "1097      []     NA  \n",
       "994       []     NA  \n",
       "492       []     NA  \n",
       "257       []     NA  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows where dsType is NA\n",
    "\n",
    "lastDF = newDF[newDF.dsType == \"NA\"]\n",
    "lastDF.shape\n",
    "lastDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Challenge</th>\n",
       "      <th>SubChallenge</th>\n",
       "      <th>ProjURL</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>oldIndex</th>\n",
       "      <th>fullDS</th>\n",
       "      <th>newIndex</th>\n",
       "      <th>permuteIdx</th>\n",
       "      <th>vocabDS</th>\n",
       "      <th>dsType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>NewModels</td>\n",
       "      <td>https://devpost.com/software/connecting-future...</td>\n",
       "      <td>Connecting Futures</td>\n",
       "      <td>The problem your project solves\\nProblem: Huge...</td>\n",
       "      <td>963</td>\n",
       "      <td>[11787, 11798, 11507, 10180, 11645, 11201, 113...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[10180, 3114, 8032, 10530, 10285, 10530, 10285...</td>\n",
       "      <td>Tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Health</td>\n",
       "      <td>Other</td>\n",
       "      <td>https://devpost.com/software/aurum-wellness</td>\n",
       "      <td>Aurum Wellness</td>\n",
       "      <td>Inspiration - Always wanted to work in the spa...</td>\n",
       "      <td>889</td>\n",
       "      <td>[11058, 11789, 11358, 10434, 11268, 11577, 114...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[10434, 10434, 10176, 8544, 10517]</td>\n",
       "      <td>Tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business</td>\n",
       "      <td>Other</td>\n",
       "      <td>https://devpost.com/software/desktop-mobile-co...</td>\n",
       "      <td>Desktop mobile computer</td>\n",
       "      <td>The problem\\nThere is a problem that need shor...</td>\n",
       "      <td>1269</td>\n",
       "      <td>[11787, 11787, 11800, 11780, 10482, 11532, 116...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[10482, 4194, 9529, 6383, 10505, 8577, 10529, ...</td>\n",
       "      <td>Tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cohesion</td>\n",
       "      <td>FakeNews</td>\n",
       "      <td>https://devpost.com/software/fact-o-meter-47w15x</td>\n",
       "      <td>Fact-O-Meter</td>\n",
       "      <td>The story of Pinocchio and his nose:\\nFake New...</td>\n",
       "      <td>1435</td>\n",
       "      <td>[10628, 11144, 9579, 4649, 645, 10023, 10, 117...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[9579, 4649, 645, 10023, 10, 9042, 10211, 1011...</td>\n",
       "      <td>Tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Health</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>https://devpost.com/software/tracejyu</td>\n",
       "      <td>TraceJYU</td>\n",
       "      <td>Inspiration\\nWe are inspired by the need to fi...</td>\n",
       "      <td>62</td>\n",
       "      <td>[11275, 11767, 11800, 11772, 11720, 10823, 116...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[9684, 10304, 9091, 9997, 6891, 7581, 10327, 9...</td>\n",
       "      <td>Tr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Challenge SubChallenge                                            ProjURL  \\\n",
       "0  Business    NewModels  https://devpost.com/software/connecting-future...   \n",
       "1    Health        Other        https://devpost.com/software/aurum-wellness   \n",
       "2  Business        Other  https://devpost.com/software/desktop-mobile-co...   \n",
       "3  Cohesion     FakeNews   https://devpost.com/software/fact-o-meter-47w15x   \n",
       "4    Health    Equipment              https://devpost.com/software/tracejyu   \n",
       "\n",
       "                     title                                               text  \\\n",
       "0       Connecting Futures  The problem your project solves\\nProblem: Huge...   \n",
       "1           Aurum Wellness  Inspiration - Always wanted to work in the spa...   \n",
       "2  Desktop mobile computer  The problem\\nThere is a problem that need shor...   \n",
       "3             Fact-O-Meter  The story of Pinocchio and his nose:\\nFake New...   \n",
       "4                 TraceJYU  Inspiration\\nWe are inspired by the need to fi...   \n",
       "\n",
       "   oldIndex                                             fullDS  newIndex  \\\n",
       "0       963  [11787, 11798, 11507, 10180, 11645, 11201, 113...         0   \n",
       "1       889  [11058, 11789, 11358, 10434, 11268, 11577, 114...         1   \n",
       "2      1269  [11787, 11787, 11800, 11780, 10482, 11532, 116...         2   \n",
       "3      1435  [10628, 11144, 9579, 4649, 645, 10023, 10, 117...         3   \n",
       "4        62  [11275, 11767, 11800, 11772, 11720, 10823, 116...         4   \n",
       "\n",
       "   permuteIdx                                            vocabDS dsType  \n",
       "0           0  [10180, 3114, 8032, 10530, 10285, 10530, 10285...     Tr  \n",
       "1           1                 [10434, 10434, 10176, 8544, 10517]     Tr  \n",
       "2           2  [10482, 4194, 9529, 6383, 10505, 8577, 10529, ...     Tr  \n",
       "3           3  [9579, 4649, 645, 10023, 10, 9042, 10211, 1011...     Tr  \n",
       "4           4  [9684, 10304, 9091, 9997, 6891, 7581, 10327, 9...     Tr  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only rows with non-NA dsType (these correspond to the rows for which topic embeddings were found)\n",
    "keepDF = newDF[newDF.dsType != \"NA\"].reset_index(drop = True)\n",
    "keepDF.shape\n",
    "keepDF = keepDF.assign(newIndex = keepDF.index)\n",
    "keepDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Challenge</th>\n",
       "      <th>ProjURL</th>\n",
       "      <th>SubChallenge</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_10</th>\n",
       "      <th>Topic_100</th>\n",
       "      <th>Topic_101</th>\n",
       "      <th>Topic_102</th>\n",
       "      <th>Topic_103</th>\n",
       "      <th>Topic_104</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_98</th>\n",
       "      <th>Topic_99</th>\n",
       "      <th>dsType</th>\n",
       "      <th>fullDS</th>\n",
       "      <th>newIndex</th>\n",
       "      <th>oldIndex</th>\n",
       "      <th>permuteIdx</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>vocabDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>https://devpost.com/software/connecting-future...</td>\n",
       "      <td>NewModels</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.006464</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>Tr</td>\n",
       "      <td>[11787, 11798, 11507, 10180, 11645, 11201, 113...</td>\n",
       "      <td>0</td>\n",
       "      <td>963</td>\n",
       "      <td>0</td>\n",
       "      <td>The problem your project solves\\nProblem: Huge...</td>\n",
       "      <td>Connecting Futures</td>\n",
       "      <td>[10180, 3114, 8032, 10530, 10285, 10530, 10285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Health</td>\n",
       "      <td>https://devpost.com/software/aurum-wellness</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.006727</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>0.006543</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>0.006533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006611</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>Tr</td>\n",
       "      <td>[11058, 11789, 11358, 10434, 11268, 11577, 114...</td>\n",
       "      <td>1</td>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>Inspiration - Always wanted to work in the spa...</td>\n",
       "      <td>Aurum Wellness</td>\n",
       "      <td>[10434, 10434, 10176, 8544, 10517]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business</td>\n",
       "      <td>https://devpost.com/software/desktop-mobile-co...</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.006727</td>\n",
       "      <td>0.006606</td>\n",
       "      <td>0.006464</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.006542</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006607</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>Tr</td>\n",
       "      <td>[11787, 11787, 11800, 11780, 10482, 11532, 116...</td>\n",
       "      <td>2</td>\n",
       "      <td>1269</td>\n",
       "      <td>2</td>\n",
       "      <td>The problem\\nThere is a problem that need shor...</td>\n",
       "      <td>Desktop mobile computer</td>\n",
       "      <td>[10482, 4194, 9529, 6383, 10505, 8577, 10529, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cohesion</td>\n",
       "      <td>https://devpost.com/software/fact-o-meter-47w15x</td>\n",
       "      <td>FakeNews</td>\n",
       "      <td>0.006727</td>\n",
       "      <td>0.006609</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>Tr</td>\n",
       "      <td>[10628, 11144, 9579, 4649, 645, 10023, 10, 117...</td>\n",
       "      <td>3</td>\n",
       "      <td>1435</td>\n",
       "      <td>3</td>\n",
       "      <td>The story of Pinocchio and his nose:\\nFake New...</td>\n",
       "      <td>Fact-O-Meter</td>\n",
       "      <td>[9579, 4649, 645, 10023, 10, 9042, 10211, 1011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Health</td>\n",
       "      <td>https://devpost.com/software/tracejyu</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0.006604</td>\n",
       "      <td>0.006464</td>\n",
       "      <td>0.006848</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006607</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>Tr</td>\n",
       "      <td>[11275, 11767, 11800, 11772, 11720, 10823, 116...</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>Inspiration\\nWe are inspired by the need to fi...</td>\n",
       "      <td>TraceJYU</td>\n",
       "      <td>[9684, 10304, 9091, 9997, 6891, 7581, 10327, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Challenge                                            ProjURL SubChallenge  \\\n",
       "0  Business  https://devpost.com/software/connecting-future...    NewModels   \n",
       "1    Health        https://devpost.com/software/aurum-wellness        Other   \n",
       "2  Business  https://devpost.com/software/desktop-mobile-co...        Other   \n",
       "3  Cohesion   https://devpost.com/software/fact-o-meter-47w15x     FakeNews   \n",
       "4    Health              https://devpost.com/software/tracejyu    Equipment   \n",
       "\n",
       "    Topic_1  Topic_10  Topic_100  Topic_101  Topic_102  Topic_103  Topic_104  \\\n",
       "0  0.006726  0.006608   0.006464   0.006847   0.006541   0.006620   0.006534   \n",
       "1  0.006727  0.006603   0.006465   0.006852   0.006543   0.006622   0.006533   \n",
       "2  0.006727  0.006606   0.006464   0.006847   0.006542   0.006622   0.006536   \n",
       "3  0.006727  0.006609   0.006463   0.006846   0.006541   0.006619   0.006534   \n",
       "4  0.006729  0.006604   0.006464   0.006848   0.006540   0.006621   0.006537   \n",
       "\n",
       "                         ...                          Topic_98  Topic_99  \\\n",
       "0                        ...                          0.006608  0.006843   \n",
       "1                        ...                          0.006611  0.006846   \n",
       "2                        ...                          0.006607  0.006844   \n",
       "3                        ...                          0.006608  0.006842   \n",
       "4                        ...                          0.006607  0.006844   \n",
       "\n",
       "   dsType                                             fullDS  newIndex  \\\n",
       "0      Tr  [11787, 11798, 11507, 10180, 11645, 11201, 113...         0   \n",
       "1      Tr  [11058, 11789, 11358, 10434, 11268, 11577, 114...         1   \n",
       "2      Tr  [11787, 11787, 11800, 11780, 10482, 11532, 116...         2   \n",
       "3      Tr  [10628, 11144, 9579, 4649, 645, 10023, 10, 117...         3   \n",
       "4      Tr  [11275, 11767, 11800, 11772, 11720, 10823, 116...         4   \n",
       "\n",
       "   oldIndex  permuteIdx                                               text  \\\n",
       "0       963           0  The problem your project solves\\nProblem: Huge...   \n",
       "1       889           1  Inspiration - Always wanted to work in the spa...   \n",
       "2      1269           2  The problem\\nThere is a problem that need shor...   \n",
       "3      1435           3  The story of Pinocchio and his nose:\\nFake New...   \n",
       "4        62           4  Inspiration\\nWe are inspired by the need to fi...   \n",
       "\n",
       "                     title                                            vocabDS  \n",
       "0       Connecting Futures  [10180, 3114, 8032, 10530, 10285, 10530, 10285...  \n",
       "1           Aurum Wellness                 [10434, 10434, 10176, 8544, 10517]  \n",
       "2  Desktop mobile computer  [10482, 4194, 9529, 6383, 10505, 8577, 10529, ...  \n",
       "3             Fact-O-Meter  [9579, 4649, 645, 10023, 10, 9042, 10211, 1011...  \n",
       "4                 TraceJYU  [9684, 10304, 9091, 9997, 6891, 7581, 10327, 9...  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge thetaDF with the documents DF\n",
    "joinedDF = pd.merge(keepDF, thetaDF, how='left', on= [\"newIndex\"], left_on=None, right_on=None,\n",
    "         left_index=False, right_index=False, sort=True,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "\n",
    "joinedDF = joinedDF.append(lastDF).reset_index(drop = True).fillna(0)\n",
    "joinedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file\n",
    "path_save = os.path.join(args.save_path, \"ThetaBeta\", args.load_from) + \"_docTopics.csv\"\n",
    "joinedDF.to_csv(path_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
